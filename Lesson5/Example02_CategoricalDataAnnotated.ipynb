{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4a3f68",
   "metadata": {},
   "source": [
    "# Working with Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78913e",
   "metadata": {},
   "source": [
    "Example code adapts from a source (https://pbpython.com/pandas_dtypes_cat.html) and aims to illustrate how to work with categorical data in a Pandas DataFrame efficiently. Categorical data represents data that falls into categories or groups and is often used to store data with a limited number of unique values, such as colors, countries, or product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6270ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Working with categorical data - Example adapted from: https://pbpython.com/pandas_dtypes_cat.html\n",
    "# import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbda33a",
   "metadata": {},
   "source": [
    "- requests: This module allows the code to send HTTP requests and receive responses from web servers. It is used here to fetch data from a remote location.\n",
    "- StringIO: This module provides an in-memory buffer for text data. It is used to handle string data as if it were a file.\n",
    "- BytesIO: This module provides an in-memory buffer for binary data. It is used to handle binary data as if it were a file.\n",
    "- ZipFile: This module allows the code to work with ZIP-compressed files, which is useful when dealing with compressed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87115380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining location of dataset \n",
    "filepath=\"/opt/datasets/ist652/Categories/medical.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fb5bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(filepath,compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6171c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Change_Type</th>\n",
       "      <th>Covered_Recipient_Type</th>\n",
       "      <th>Recipient_Primary_Business_Street_Address_Line1</th>\n",
       "      <th>Recipient_City</th>\n",
       "      <th>Recipient_State</th>\n",
       "      <th>Recipient_Zip_Code</th>\n",
       "      <th>Recipient_Country</th>\n",
       "      <th>Principal_Investigator_1_Profile_ID</th>\n",
       "      <th>Principal_Investigator_1_First_Name</th>\n",
       "      <th>Principal_Investigator_1_Last_Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Amount_of_Payment_USDollars</th>\n",
       "      <th>Date_of_Payment</th>\n",
       "      <th>Form_of_Payment_or_Transfer_of_Value</th>\n",
       "      <th>Preclinical_Research_Indicator</th>\n",
       "      <th>Delay_in_Publication_Indicator</th>\n",
       "      <th>Name_of_Study</th>\n",
       "      <th>Dispute_Status_for_Publication</th>\n",
       "      <th>Record_ID</th>\n",
       "      <th>Program_Year</th>\n",
       "      <th>Payment_Publication_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Covered Recipient Teaching Hospital</td>\n",
       "      <td>450 Brookline Ave</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>02215</td>\n",
       "      <td>United States</td>\n",
       "      <td>754443.0</td>\n",
       "      <td>OSAMA</td>\n",
       "      <td>RAHMA</td>\n",
       "      <td>...</td>\n",
       "      <td>21.00</td>\n",
       "      <td>12/08/2018</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Safety, Pharmacokinetics, and Pharmacodynamics...</td>\n",
       "      <td>No</td>\n",
       "      <td>576946373</td>\n",
       "      <td>2018</td>\n",
       "      <td>01/22/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNCHANGED</td>\n",
       "      <td>Covered Recipient Teaching Hospital</td>\n",
       "      <td>601 EAST ROLLINS STREET</td>\n",
       "      <td>ORLANDO</td>\n",
       "      <td>FL</td>\n",
       "      <td>32803</td>\n",
       "      <td>United States</td>\n",
       "      <td>155977.0</td>\n",
       "      <td>NAUSHAD</td>\n",
       "      <td>SHAIK</td>\n",
       "      <td>...</td>\n",
       "      <td>101.25</td>\n",
       "      <td>10/10/2018</td>\n",
       "      <td>Cash or cash equivalent</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>QP ExCELs</td>\n",
       "      <td>No</td>\n",
       "      <td>609099103</td>\n",
       "      <td>2018</td>\n",
       "      <td>01/22/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Change_Type               Covered_Recipient_Type  \\\n",
       "0   UNCHANGED  Covered Recipient Teaching Hospital   \n",
       "1   UNCHANGED  Covered Recipient Teaching Hospital   \n",
       "\n",
       "  Recipient_Primary_Business_Street_Address_Line1 Recipient_City  \\\n",
       "0                               450 Brookline Ave         Boston   \n",
       "1                         601 EAST ROLLINS STREET        ORLANDO   \n",
       "\n",
       "  Recipient_State Recipient_Zip_Code Recipient_Country  \\\n",
       "0              MA              02215     United States   \n",
       "1              FL              32803     United States   \n",
       "\n",
       "   Principal_Investigator_1_Profile_ID Principal_Investigator_1_First_Name  \\\n",
       "0                             754443.0                               OSAMA   \n",
       "1                             155977.0                             NAUSHAD   \n",
       "\n",
       "  Principal_Investigator_1_Last_Name  ... Total_Amount_of_Payment_USDollars  \\\n",
       "0                              RAHMA  ...                             21.00   \n",
       "1                              SHAIK  ...                            101.25   \n",
       "\n",
       "  Date_of_Payment Form_of_Payment_or_Transfer_of_Value  \\\n",
       "0      12/08/2018              Cash or cash equivalent   \n",
       "1      10/10/2018              Cash or cash equivalent   \n",
       "\n",
       "  Preclinical_Research_Indicator Delay_in_Publication_Indicator  \\\n",
       "0                             No                             No   \n",
       "1                             No                             No   \n",
       "\n",
       "                                       Name_of_Study  \\\n",
       "0  Safety, Pharmacokinetics, and Pharmacodynamics...   \n",
       "1                                          QP ExCELs   \n",
       "\n",
       "  Dispute_Status_for_Publication  Record_ID Program_Year  \\\n",
       "0                             No  576946373         2018   \n",
       "1                             No  609099103         2018   \n",
       "\n",
       "   Payment_Publication_Date  \n",
       "0                01/22/2021  \n",
       "1                01/22/2021  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abandoned-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 611664 entries, 0 to 611663\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                                            Non-Null Count   Dtype  \n",
      "---  ------                                                            --------------   -----  \n",
      " 0   Change_Type                                                       611664 non-null  object \n",
      " 1   Covered_Recipient_Type                                            611664 non-null  object \n",
      " 2   Recipient_Primary_Business_Street_Address_Line1                   611460 non-null  object \n",
      " 3   Recipient_City                                                    611460 non-null  object \n",
      " 4   Recipient_State                                                   610452 non-null  object \n",
      " 5   Recipient_Zip_Code                                                610452 non-null  object \n",
      " 6   Recipient_Country                                                 611460 non-null  object \n",
      " 7   Principal_Investigator_1_Profile_ID                               576780 non-null  float64\n",
      " 8   Principal_Investigator_1_First_Name                               576778 non-null  object \n",
      " 9   Principal_Investigator_1_Last_Name                                576780 non-null  object \n",
      " 10  Principal_Investigator_1_Business_Street_Address_Line1            576780 non-null  object \n",
      " 11  Principal_Investigator_1_City                                     576778 non-null  object \n",
      " 12  Principal_Investigator_1_State                                    576752 non-null  object \n",
      " 13  Principal_Investigator_1_Zip_Code                                 576752 non-null  object \n",
      " 14  Principal_Investigator_1_Country                                  576780 non-null  object \n",
      " 15  Principal_Investigator_1_Primary_Type                             576780 non-null  object \n",
      " 16  Principal_Investigator_1_Specialty                                576771 non-null  object \n",
      " 17  Principal_Investigator_1_License_State_code1                      576780 non-null  object \n",
      " 18  Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name         611664 non-null  object \n",
      " 19  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID       611664 non-null  int64  \n",
      " 20  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name     611664 non-null  object \n",
      " 21  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State    569057 non-null  object \n",
      " 22  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country  611664 non-null  object \n",
      " 23  Related_Product_Indicator                                         611664 non-null  object \n",
      " 24  Total_Amount_of_Payment_USDollars                                 611664 non-null  float64\n",
      " 25  Date_of_Payment                                                   611664 non-null  object \n",
      " 26  Form_of_Payment_or_Transfer_of_Value                              611664 non-null  object \n",
      " 27  Preclinical_Research_Indicator                                    611664 non-null  object \n",
      " 28  Delay_in_Publication_Indicator                                    611664 non-null  object \n",
      " 29  Name_of_Study                                                     606836 non-null  object \n",
      " 30  Dispute_Status_for_Publication                                    611664 non-null  object \n",
      " 31  Record_ID                                                         611664 non-null  int64  \n",
      " 32  Program_Year                                                      611664 non-null  int64  \n",
      " 33  Payment_Publication_Date                                          611664 non-null  object \n",
      "dtypes: float64(2), int64(3), object(29)\n",
      "memory usage: 158.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-atlanta",
   "metadata": {},
   "source": [
    "#### Let's see which columns may be good candidates for a categorical data type by counting how many unique entries/values are in each column and also using that information to determine if there are some columns that are not relevant.\n",
    "\n",
    "\n",
    "#### Code Overview\n",
    "1. Creates a DataFrame `unique_counts` using the `pd.DataFrame.from_records()` method.\n",
    "2. The `from_records()` method takes a list of tuples as input, where each tuple represents a row in the DataFrame. In this case, the list of tuples is generated using a list comprehension.\n",
    "3. The list comprehension iterates over the columns of the DataFrame `df` and creates a tuple for each column. The tuple contains the column name and the number of unique values in that column (`df[col].nunique()`).\n",
    "4. The resulting list of tuples is passed to the `from_records()` method, which creates the DataFrame `unique_counts`.\n",
    "5. The `columns` parameter is used to specify the column names of the resulting DataFrame.\n",
    "6. The `sort_values()` method is called on the `unique_counts` DataFrame to sort it in ascending order based on the `Num_Unique` column.\n",
    "\n",
    "In summary, the code takes a DataFrame `df` as input and creates a new DataFrame `unique_counts`, which contains two columns: 'Column_Name' and 'Num_Unique'. Each row of `unique_counts` represents a column from the original DataFrame `df`, and the 'Num_Unique' column shows the count of unique values in that particular column. The resulting DataFrame is sorted in ascending order based on the number of unique values, making it easier to identify which columns have the least number of unique values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affiliated-respondent",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_counts = pd.DataFrame.from_records([(col, df[col].nunique()) for col in df.columns],\n",
    "                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hollywood-republican",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_Name</th>\n",
       "      <th>Num_Unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Payment_Publication_Date</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Delay_in_Publication_Indicator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Program_Year</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dispute_Status_for_Publication</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Preclinical_Research_Indicator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Form_of_Payment_or_Transfer_of_Value</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Change_Type</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covered_Recipient_Type</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Principal_Investigator_1_Primary_Type</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Principal_Investigator_1_Country</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recipient_Country</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recipient_State</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Principal_Investigator_1_State</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Principal_Investigator_1_License_State_code1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Principal_Investigator_1_Specialty</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Date_of_Payment</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Submitting_Applicable_Manufacturer_or_Applicab...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Principal_Investigator_1_City</td>\n",
       "      <td>4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipient_City</td>\n",
       "      <td>4349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal_Investigator_1_First_Name</td>\n",
       "      <td>8587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recipient_Zip_Code</td>\n",
       "      <td>13339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Principal_Investigator_1_Zip_Code</td>\n",
       "      <td>13744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Name_of_Study</td>\n",
       "      <td>13896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal_Investigator_1_Last_Name</td>\n",
       "      <td>21842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Principal_Investigator_1_Business_Street_Addre...</td>\n",
       "      <td>28299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Principal_Investigator_1_Profile_ID</td>\n",
       "      <td>30291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recipient_Primary_Business_Street_Address_Line1</td>\n",
       "      <td>38771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Total_Amount_of_Payment_USDollars</td>\n",
       "      <td>157158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Record_ID</td>\n",
       "      <td>611664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Column_Name  Num_Unique\n",
       "33                           Payment_Publication_Date           1\n",
       "28                     Delay_in_Publication_Indicator           1\n",
       "32                                       Program_Year           1\n",
       "30                     Dispute_Status_for_Publication           2\n",
       "27                     Preclinical_Research_Indicator           2\n",
       "26               Form_of_Payment_or_Transfer_of_Value           2\n",
       "23                          Related_Product_Indicator           2\n",
       "0                                         Change_Type           3\n",
       "1                              Covered_Recipient_Type           4\n",
       "15              Principal_Investigator_1_Primary_Type           6\n",
       "14                   Principal_Investigator_1_Country           7\n",
       "6                                   Recipient_Country          11\n",
       "22  Applicable_Manufacturer_or_Applicable_GPO_Maki...          21\n",
       "21  Applicable_Manufacturer_or_Applicable_GPO_Maki...          35\n",
       "4                                     Recipient_State          54\n",
       "12                     Principal_Investigator_1_State          54\n",
       "17       Principal_Investigator_1_License_State_code1          54\n",
       "16                 Principal_Investigator_1_Specialty         215\n",
       "25                                    Date_of_Payment         365\n",
       "18  Submitting_Applicable_Manufacturer_or_Applicab...         600\n",
       "19  Applicable_Manufacturer_or_Applicable_GPO_Maki...         658\n",
       "20  Applicable_Manufacturer_or_Applicable_GPO_Maki...         670\n",
       "11                      Principal_Investigator_1_City        4011\n",
       "3                                      Recipient_City        4349\n",
       "8                 Principal_Investigator_1_First_Name        8587\n",
       "5                                  Recipient_Zip_Code       13339\n",
       "13                  Principal_Investigator_1_Zip_Code       13744\n",
       "29                                      Name_of_Study       13896\n",
       "9                  Principal_Investigator_1_Last_Name       21842\n",
       "10  Principal_Investigator_1_Business_Street_Addre...       28299\n",
       "7                 Principal_Investigator_1_Profile_ID       30291\n",
       "2     Recipient_Primary_Business_Street_Address_Line1       38771\n",
       "24                  Total_Amount_of_Payment_USDollars      157158\n",
       "31                                          Record_ID      611664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba62c36",
   "metadata": {},
   "source": [
    " `unique_counts = pd.DataFrame.from_records([(col, df[col].nunique()) for col in df.columns], columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])`:\n",
    "\n",
    "   a. `pd.DataFrame.from_records(...)`: This part of the code creates a new DataFrame from a list of records. The records are generated using a list comprehension, which iterates over the columns of the original DataFrame `df`.\n",
    "\n",
    "   b. `(col, df[col].nunique())`: For each column `col` in the DataFrame `df`, a tuple `(col, df[col].nunique())` is created. The first element of the tuple is the column name (`col`), and the second element is the number of unique values in that column, obtained using the `nunique()` method of pandas.\n",
    "\n",
    "   c. `columns=['Column_Name', 'Num_Unique']`: This specifies the column names for the new DataFrame. The first column will be named 'Column_Name', and the second column will be named 'Num_Unique'.\n",
    "\n",
    "   d. `.sort_values(by=['Num_Unique'])`: After creating the DataFrame, this part sorts the DataFrame based on the 'Num_Unique' column in ascending order. This means that the DataFrame will be ordered from the columns with the least unique values to the columns with the most unique values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8227e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop columns that don't bring any new information\n",
    "df.drop(['Payment_Publication_Date','Delay_in_Publication_Indicator','Program_Year'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b3b57",
   "metadata": {},
   "source": [
    "#### Dropping Columns:\n",
    "The main purpose of this code is to drop specific columns from the DataFrame `df`. The columns being dropped are `'Payment_Publication_Date'`, `'Delay_in_Publication_Indicator'`, and `'Program_Year'`.\n",
    "\n",
    "#### Syntax of the `drop()` method:\n",
    "\n",
    "The `drop()` method  is used to remove rows or columns from a DataFrame. Its syntax is as follows:\n",
    "\n",
    "```python\n",
    "DataFrame.drop(labels, axis=0, index=None, columns=None, inplace=False)\n",
    "```\n",
    "\n",
    "- `labels`: This parameter specifies the rows or columns to be removed. In our case, it's the list of column names `['Payment_Publication_Date', 'Delay_in_Publication_Indicator', 'Program_Year']`.\n",
    "- `axis`: This parameter indicates whether we want to drop rows (axis=0) or columns (axis=1). In this code, `axis=1` means we are dropping columns.\n",
    "- `index` and `columns`: These parameters are used to specify the labels of rows and columns to drop. Since we are using `axis=1`, the `columns` parameter is the one we are interested in, and we pass the list of column names to it.\n",
    "- `inplace`: This parameter determines whether the DataFrame is modified in place (True) or a new DataFrame with the specified changes is returned (False). In this case, `inplace=True`, so the changes will be made to the original `df` DataFrame.\n",
    "\n",
    "#### Functionality :\n",
    "\n",
    "The purpose of dropping these specific columns from the DataFrame could vary depending on the data and the context of the analysis. Some common reasons for dropping columns include:\n",
    "\n",
    "1. **Redundant Information**: If the columns `'Payment_Publication_Date'`, `'Delay_in_Publication_Indicator'`, and `'Program_Year'` contain redundant or unnecessary information that is already captured in other columns, it makes sense to drop them to reduce data redundancy and save memory.\n",
    "\n",
    "2. **Missing or Irrelevant Data**: If these columns have a significant number of missing values or contain data that is irrelevant to the current analysis, dropping them can improve the quality and relevance of the remaining data.\n",
    "\n",
    "3. **Data Privacy**: In some cases, certain columns may contain sensitive or personally identifiable information (PII). To protect data privacy, those columns might be dropped.\n",
    "\n",
    "4. **Model Training**: When preparing data for machine learning models, dropping irrelevant or non-predictive columns can improve model performance and reduce overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d252b53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 611664 entries, 0 to 611663\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                                            Non-Null Count   Dtype  \n",
      "---  ------                                                            --------------   -----  \n",
      " 0   Change_Type                                                       611664 non-null  object \n",
      " 1   Covered_Recipient_Type                                            611664 non-null  object \n",
      " 2   Recipient_Primary_Business_Street_Address_Line1                   611460 non-null  object \n",
      " 3   Recipient_City                                                    611460 non-null  object \n",
      " 4   Recipient_State                                                   610452 non-null  object \n",
      " 5   Recipient_Zip_Code                                                610452 non-null  object \n",
      " 6   Recipient_Country                                                 611460 non-null  object \n",
      " 7   Principal_Investigator_1_Profile_ID                               576780 non-null  float64\n",
      " 8   Principal_Investigator_1_First_Name                               576778 non-null  object \n",
      " 9   Principal_Investigator_1_Last_Name                                576780 non-null  object \n",
      " 10  Principal_Investigator_1_Business_Street_Address_Line1            576780 non-null  object \n",
      " 11  Principal_Investigator_1_City                                     576778 non-null  object \n",
      " 12  Principal_Investigator_1_State                                    576752 non-null  object \n",
      " 13  Principal_Investigator_1_Zip_Code                                 576752 non-null  object \n",
      " 14  Principal_Investigator_1_Country                                  576780 non-null  object \n",
      " 15  Principal_Investigator_1_Primary_Type                             576780 non-null  object \n",
      " 16  Principal_Investigator_1_Specialty                                576771 non-null  object \n",
      " 17  Principal_Investigator_1_License_State_code1                      576780 non-null  object \n",
      " 18  Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name         611664 non-null  object \n",
      " 19  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID       611664 non-null  int64  \n",
      " 20  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name     611664 non-null  object \n",
      " 21  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State    569057 non-null  object \n",
      " 22  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country  611664 non-null  object \n",
      " 23  Related_Product_Indicator                                         611664 non-null  object \n",
      " 24  Total_Amount_of_Payment_USDollars                                 611664 non-null  float64\n",
      " 25  Date_of_Payment                                                   611664 non-null  object \n",
      " 26  Form_of_Payment_or_Transfer_of_Value                              611664 non-null  object \n",
      " 27  Preclinical_Research_Indicator                                    611664 non-null  object \n",
      " 28  Name_of_Study                                                     606826 non-null  object \n",
      " 29  Dispute_Status_for_Publication                                    611664 non-null  object \n",
      " 30  Record_ID                                                         611664 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(27)\n",
      "memory usage: 144.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-fireplace",
   "metadata": {},
   "source": [
    "### There is a big jump in unique values when we get to 670. We will use that as the threshold (actually, we will make the threshold 700) for conversion to a Categorical values column (except for columns that have date/time based information). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "european-evanescence",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_to_exclude = ['Date_of_Payment']\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 700 and col not in cols_to_exclude:\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d90c10",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "1. `cols_to_exclude = ['Date_of_Payment']`: This line initializes a list `cols_to_exclude` containing the column names that should be excluded from the process. In this case, it contains only one item, which is `'Date_of_Payment'`. The purpose of this list is to prevent the column with the name `'Date_of_Payment'` from being converted to the 'category' data type.\n",
    "\n",
    "2. `for col in df.columns:`: This line starts a loop that iterates over each column in the DataFrame `df`.\n",
    "\n",
    "3. `if df[col].nunique() < 700 and col not in cols_to_exclude:`: This is an `if` statement that checks two conditions:\n",
    "   - `df[col].nunique() < 700`: It checks if the number of unique values in the current column (`col`) is less than 700. The `nunique()` method is used to count the number of unique values in a column.\n",
    "   - `col not in cols_to_exclude`: It checks if the current column (`col`) is not in the `cols_to_exclude` list. This condition ensures that the column `'Date_of_Payment'` is not processed.\n",
    "\n",
    "4. `df[col] = df[col].astype('category')`: If both conditions in the `if` statement are true, this line converts the data type of the current column (`col`) to `'category'`. The 'category' data type in pandas is a special data type used for categorical variables, which can significantly reduce memory usage and speed up certain operations on the column.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "The code's main purpose is to optimize memory usage and improve performance for columns in a  DataFrame `df`. It does this by converting columns with a low number of unique values (less than 700) to the 'category' data type. By using the 'category' data type, pandas can efficiently represent the categorical variables, which can be beneficial for data sets with repetitive or limited unique values.\n",
    "\n",
    "The code iterates through each column in the DataFrame `df`. For each column, it checks two conditions:\n",
    "- Whether the number of unique values in the column is less than 700.\n",
    "- Whether the column is not named `'Date_of_Payment'`.\n",
    "\n",
    "If both conditions are met, the code converts the data type of that column to `'category'`.\n",
    "\n",
    "### Functionality:\n",
    "\n",
    "1. **Memory optimization**: By converting columns with low cardinality (few unique values) to the 'category' data type, the code helps reduce memory usage. The 'category' type uses integer-based codes internally to represent the categories, rather than storing each category as a string, leading to more efficient memory utilization.\n",
    "\n",
    "2. **Performance improvement**: Using the 'category' data type for columns can speed up certain operations in pandas. For example, grouping, filtering, and merging data frames with categorical columns can be faster due to the internal integer representation of categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "joined-saint",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 611664 entries, 0 to 611663\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                                            Non-Null Count   Dtype   \n",
      "---  ------                                                            --------------   -----   \n",
      " 0   Change_Type                                                       611664 non-null  category\n",
      " 1   Covered_Recipient_Type                                            611664 non-null  category\n",
      " 2   Recipient_Primary_Business_Street_Address_Line1                   611460 non-null  object  \n",
      " 3   Recipient_City                                                    611460 non-null  object  \n",
      " 4   Recipient_State                                                   610452 non-null  category\n",
      " 5   Recipient_Zip_Code                                                610452 non-null  object  \n",
      " 6   Recipient_Country                                                 611460 non-null  category\n",
      " 7   Principal_Investigator_1_Profile_ID                               576780 non-null  float64 \n",
      " 8   Principal_Investigator_1_First_Name                               576778 non-null  object  \n",
      " 9   Principal_Investigator_1_Last_Name                                576780 non-null  object  \n",
      " 10  Principal_Investigator_1_Business_Street_Address_Line1            576780 non-null  object  \n",
      " 11  Principal_Investigator_1_City                                     576778 non-null  object  \n",
      " 12  Principal_Investigator_1_State                                    576752 non-null  category\n",
      " 13  Principal_Investigator_1_Zip_Code                                 576752 non-null  object  \n",
      " 14  Principal_Investigator_1_Country                                  576780 non-null  category\n",
      " 15  Principal_Investigator_1_Primary_Type                             576780 non-null  category\n",
      " 16  Principal_Investigator_1_Specialty                                576771 non-null  category\n",
      " 17  Principal_Investigator_1_License_State_code1                      576780 non-null  category\n",
      " 18  Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name         611664 non-null  category\n",
      " 19  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID       611664 non-null  category\n",
      " 20  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name     611664 non-null  category\n",
      " 21  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State    569057 non-null  category\n",
      " 22  Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country  611664 non-null  category\n",
      " 23  Related_Product_Indicator                                         611664 non-null  category\n",
      " 24  Total_Amount_of_Payment_USDollars                                 611664 non-null  float64 \n",
      " 25  Date_of_Payment                                                   611664 non-null  object  \n",
      " 26  Form_of_Payment_or_Transfer_of_Value                              611664 non-null  category\n",
      " 27  Preclinical_Research_Indicator                                    611664 non-null  category\n",
      " 28  Delay_in_Publication_Indicator                                    611664 non-null  category\n",
      " 29  Name_of_Study                                                     606826 non-null  object  \n",
      " 30  Dispute_Status_for_Publication                                    611664 non-null  category\n",
      " 31  Record_ID                                                         611664 non-null  int64   \n",
      " 32  Program_Year                                                      611664 non-null  category\n",
      " 33  Payment_Publication_Date                                          611664 non-null  category\n",
      "dtypes: category(21), float64(2), int64(1), object(10)\n",
      "memory usage: 75.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-minutes",
   "metadata": {},
   "source": [
    "Please note that by using categorical types, we have reduced the memory use of the dataframe substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legal-studio",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1075/586823689.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby('Covered_Recipient_Type')['Total_Amount_of_Payment_USDollars'].sum().to_frame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Amount_of_Payment_USDollars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covered_Recipient_Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Covered Recipient Physician</th>\n",
       "      <td>9.715687e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covered Recipient Teaching Hospital</th>\n",
       "      <td>1.258553e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-covered Recipient Entity</th>\n",
       "      <td>3.922970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-covered Recipient Individual</th>\n",
       "      <td>7.731784e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Total_Amount_of_Payment_USDollars\n",
       "Covered_Recipient_Type                                                \n",
       "Covered Recipient Physician                               9.715687e+07\n",
       "Covered Recipient Teaching Hospital                       1.258553e+09\n",
       "Non-covered Recipient Entity                              3.922970e+09\n",
       "Non-covered Recipient Individual                          7.731784e+05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of total payments made by covered recipient type\n",
    "df.groupby('Covered_Recipient_Type')['Total_Amount_of_Payment_USDollars'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a487b7",
   "metadata": {},
   "source": [
    "`groupby('Covered_Recipient_Type')`: This part of the code is using the `groupby()` function of Pandas. It groups the rows of the DataFrame `df` based on the unique values in the 'Covered_Recipient_Type' column. This operation creates separate groups for each unique recipient type in the DataFrame.\n",
    "\n",
    "`['Total_Amount_of_Payment_USDollars']`: This part specifies the column that we want to aggregate, in this case, the 'Total_Amount_of_Payment_USDollars' column. We want to calculate the sum of payments for each recipient type.\n",
    "\n",
    "`.sum()`: This function is applied to each group of recipients. It calculates the sum of the 'Total_Amount_of_Payment_USDollars' column within each group, effectively giving us the total payment made to each covered recipient type.\n",
    "\n",
    "`.to_frame()`: function is used to convert the result into a Pandas DataFrame. The resulting DataFrame will have two columns: 'Covered_Recipient_Type' and 'Total_Amount_of_Payment_USDollars'. The 'Covered_Recipient_Type' column will contain the unique recipient types, and the 'Total_Amount_of_Payment_USDollars' column will contain the corresponding total payment for each type.\n",
    "\n",
    "The final output of the code will be a summary table showing the total payments made to covered recipients based on their types.\n",
    "\n",
    "Simplified Example:\n",
    "Suppose the original DataFrame `df` looks like this:\n",
    "\n",
    "| Index | Covered_Recipient_Type | Total_Amount_of_Payment_USDollars |\n",
    "|-------|-----------------------|----------------------------------|\n",
    "| 0     | Physician             | 2000                             |\n",
    "| 1     | Hospital              | 1500                             |\n",
    "| 2     | Physician             | 3000                             |\n",
    "| 3     | Pharmacy              | 500                              |\n",
    "| 4     | Hospital              | 1000                             |\n",
    "\n",
    "After applying the given code snippet, the output DataFrame will look like this:\n",
    "\n",
    "| Covered_Recipient_Type | Total_Amount_of_Payment_USDollars |\n",
    "|-----------------------|----------------------------------|\n",
    "| Physician             | 5000                             |\n",
    "| Hospital              | 2500                             |\n",
    "| Pharmacy              | 500                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-cologne",
   "metadata": {},
   "source": [
    "To change the order of *Covered_Recipient_Type* we create a *CategoricalDtype*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "separate-ozone",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "cats_in_order = [\"Non-covered Recipient Entity\", \"Covered Recipient Teaching Hospital\",\n",
    "                 \"Covered Recipient Physician\", \"Non-covered Recipient Individual\"]\n",
    "covered_type = CategoricalDtype(categories=cats_in_order, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd813a6",
   "metadata": {},
   "source": [
    "#### Structure and Functionality:\n",
    "\n",
    "1. Importing necessary libraries:\n",
    "   The code starts by importing the required functionality from the `pandas` library. Specifically, it imports the `CategoricalDtype` class, which allows us to define custom categorical data types with ordered categories.\n",
    "\n",
    "2. Defining the categories and order:\n",
    "   The code defines a list called `cats_in_order`, which contains the names of the categories that will be used for the custom categorical data type. In this case, the categories are:\n",
    "   - \"Non-covered Recipient Entity\"\n",
    "   - \"Covered Recipient Teaching Hospital\"\n",
    "   - \"Covered Recipient Physician\"\n",
    "   - \"Non-covered Recipient Individual\"\n",
    "\n",
    "3. Creating the custom ordered categorical data type:\n",
    "   The code then creates a new `CategoricalDtype` object named `covered_type`. This object is initialized with the `categories` parameter set to the `cats_in_order` list, and the `ordered` parameter set to `True`. This means that the categories in the data type have a specific order, and operations involving this data type will take this order into account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "literary-genealogy",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['Non-covered Recipient Entity',\n",
       "                  'Covered Recipient Teaching Hospital',\n",
       "                  'Covered Recipient Physician',\n",
       "                  'Non-covered Recipient Individual'],\n",
       ", ordered=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covered_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "parliamentary-salvation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Covered_Recipient_Type'] = df['Covered_Recipient_Type'].cat.reorder_categories(cats_in_order, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ab43c",
   "metadata": {},
   "source": [
    "Let's break down the code into its individual parts:\n",
    "\n",
    "1. `df['Covered_Recipient_Type']`: This selects the column named `'Covered_Recipient_Type'` from the DataFrame `df`.\n",
    "\n",
    "2. `.cat`: The `.cat` attribute is used to access categorical data functionalities in pandas. It is used when the column contains categorical data, i.e., data with a limited and fixed number of unique values.\n",
    "\n",
    "3. `.reorder_categories(cats_in_order, ordered=True)`: This is a method of the categorical data accessor (`.cat`) that allows reordering the categories of the categorical column.\n",
    "\n",
    "    - `cats_in_order`: contains the unique values of the categorical data in the desired order.\n",
    "    \n",
    "    - `ordered=True`:  When `ordered=True`, it means that the categories have a meaningful order, which is useful in certain operations.\n",
    "\n",
    "### Notable Features/Functionality:\n",
    "1. **Categorical Data**: The code deals with categorical data in the DataFrame column `'Covered_Recipient_Type'`. Categorical data is a type of data that consists of categories or groups rather than numerical values.\n",
    "\n",
    "2. **Reordering Categories**: The main functionality of this code is to reorder the categories of the `'Covered_Recipient_Type'` column. It is useful when you want to control the display order of the categories in plots or when performing aggregations or analysis based on the category order.\n",
    "\n",
    "3. **Ordered Categories**: The code sets `ordered=True`, indicating that the categories have a meaningful order. This allows for specific operations that take advantage of the order, such as computing the median or using methods that require ordered categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlikely-airfare",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Amount_of_Payment_USDollars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covered_Recipient_Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-covered Recipient Entity</th>\n",
       "      <td>3.922970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covered Recipient Teaching Hospital</th>\n",
       "      <td>1.258553e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covered Recipient Physician</th>\n",
       "      <td>9.715687e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-covered Recipient Individual</th>\n",
       "      <td>7.731784e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Total_Amount_of_Payment_USDollars\n",
       "Covered_Recipient_Type                                                \n",
       "Non-covered Recipient Entity                              3.922970e+09\n",
       "Covered Recipient Teaching Hospital                       1.258553e+09\n",
       "Covered Recipient Physician                               9.715687e+07\n",
       "Non-covered Recipient Individual                          7.731784e+05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Covered_Recipient_Type')['Total_Amount_of_Payment_USDollars'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70310420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
